{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe\n",
    "Paper: https://nlp.stanford.edu/pubs/glove.pdf\n",
    "\n",
    "Pre-trained word vectors: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract pre-trained GloVe embeddings (822 MB): https://nlp.stanford.edu/data/glove.6B.zip\n",
    "# Save the 50-dimensional embeddings to the \"data\" folder (glove.6B.50d.txt)\n",
    "\n",
    "def read_glove_vecs(glove_file):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 50-dimensional GloVe word vectors\n",
    "words, word_to_vec_map = read_glove_vecs(\"data/glove.6B.50d.txt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "908d8e35cafed2d8dcd55d36887f8c99001effcbffca4378cf2efe6ecc18c15a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
