{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visualize word embeddings (NLP specialization; t-SNE, Week 2 of Sequence Models)\n",
    "2. De-bias word embeddings (Week 2 of Sequence Models)\n",
    "3. Neural Machine Translation (Week 3 of Sequence Models) - problem: supervised!\n",
    "\n",
    "Bleu Score for validating hypothesis?\n",
    "\n",
    "TODO:\n",
    "- second data set and / or bias axis\n",
    "- BERT\n",
    "- Repo-Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations on Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract pre-trained GloVe embeddings (822 MB): https://nlp.stanford.edu/data/glove.6B.zip\n",
    "# Save the 50-dimensional embeddings to the \"data\" folder (glove.6B.50d.txt)\n",
    "\n",
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return words, word_to_vec_map\n",
    "\n",
    "# Load the 50-dimensional GloVe word vectors\n",
    "words, word_to_vec_map = read_glove_vecs(\"data/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u \\cdot v} {||u||_2 ||v||_2} = cos(\\theta)Â \\tag{1}$$\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Returns the cosine similarity between two vectors u and v.\n",
    "        \n",
    "    Arguments:\n",
    "        u -- a word vector of shape (n,)          \n",
    "        v -- a word vector of shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Special case. Consider the case u = [0, 0], v=[0, 0]\n",
    "    if np.all(u == v):\n",
    "        return 1\n",
    "    \n",
    "    # Compute the dot product between u and v \n",
    "    dot = np.dot(u, v)\n",
    "    \n",
    "    # Compute the L2 norm of u \n",
    "    norm_u = np.sqrt(np.sum(u**2))\n",
    "    \n",
    "    # Compute the L2 norm of v \n",
    "    norm_v = np.sqrt(np.sum(v**2))\n",
    "    \n",
    "    # Avoid division by 0\n",
    "    if np.isclose(norm_u * norm_v, 0, atol=1e-32):\n",
    "        return 0\n",
    "    \n",
    "    # Compute the cosine similarity defined by formula (1) \n",
    "    cosine_similarity = dot / (norm_u * norm_v)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "-0.15\n",
      "man-doctor:\t0.71\n",
      "woman-nurse:\t0.72\n",
      "man-woman:\t0.89\n",
      "doctor-nurse:\t0.8\n",
      "man-nurse:\t0.57\n",
      "woman-doctor:\t0.73\n"
     ]
    }
   ],
   "source": [
    "# Load word vectors\n",
    "man = word_to_vec_map[\"man\"]\n",
    "doctor = word_to_vec_map[\"doctor\"]\n",
    "woman = word_to_vec_map[\"woman\"]\n",
    "nurse = word_to_vec_map[\"nurse\"]\n",
    "\n",
    "# Demonstrate gender bias\n",
    "man_to_doctor_as_woman_to_nurse = cosine_similarity(man, doctor) - cosine_similarity(woman, nurse)\n",
    "man_to_nurse_as_woman_to_doctor = cosine_similarity(man, nurse) - cosine_similarity(woman, doctor)\n",
    "\n",
    "# Print results\n",
    "print(round(man_to_doctor_as_woman_to_nurse, 2))\n",
    "print(round(man_to_nurse_as_woman_to_doctor, 2))\n",
    "print(f\"man-doctor:\\t{round(cosine_similarity(man, doctor), 2)}\")\n",
    "print(f\"woman-nurse:\\t{round(cosine_similarity(woman, nurse), 2)}\")\n",
    "print(f\"man-woman:\\t{round(cosine_similarity(man, woman), 2)}\")\n",
    "print(f\"doctor-nurse:\\t{round(cosine_similarity(doctor, nurse), 2)}\")\n",
    "print(f\"man-nurse:\\t{round(cosine_similarity(man, nurse), 2)}\")\n",
    "print(f\"woman-doctor:\\t{round(cosine_similarity(woman, doctor), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Performs the word analogy task: a is to b as c is to ____. \n",
    "    \n",
    "    Arguments:\n",
    "    word_a -- a word, string\n",
    "    word_b -- a word, string\n",
    "    word_c -- a word, string\n",
    "    word_to_vec_map -- dictionary that maps words to their corresponding vectors. \n",
    "    \n",
    "    Returns:\n",
    "    best_word --  the word such that v_b - v_a is close to v_best_word - v_c, as measured by cosine similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert words to lowercase\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "    \n",
    "    # Get the word embeddings e_a, e_b and e_c\n",
    "    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n",
    "    \n",
    "    words = word_to_vec_map.keys()\n",
    "    max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number\n",
    "    best_word = None                   # Initialize best_word with None, it will help keep track of the word to output\n",
    "    \n",
    "    # Loop over the whole word vector set\n",
    "    for w in words:   \n",
    "        # To avoid best_word being one of the input words, skip the input word_c\n",
    "        # Skip word_c from query\n",
    "        if w == word_c:\n",
    "            continue\n",
    "        \n",
    "        # Compute cosine similarity between the vector (e_b - e_a) and the vector ((w's vector representation) - e_c)  \n",
    "        cosine_sim = cosine_similarity(e_b - e_a, word_to_vec_map[w] - e_c)\n",
    "        \n",
    "        # If the cosine_sim is more than the max_cosine_sim seen so far,\n",
    "            # Then: set the new max_cosine_sim to the current cosine_sim and the best_word to the current word\n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: spain -> spanish\n",
      "india -> delhi :: japan -> tokyo\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> smaller\n"
     ]
    }
   ],
   "source": [
    "# Define triads to try analogies\n",
    "triads = [('italy', 'italian', 'spain'), ('india', 'delhi', 'japan'), ('man', 'woman', 'boy'), ('small', 'smaller', 'large')]\n",
    "\n",
    "# Print results\n",
    "for triad in triads:\n",
    "    print ('{} -> {} :: {} -> {}'.format( *triad, complete_analogy(*triad, word_to_vec_map)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiasing Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The debiasing algorithm is from Bolukbasi et al., 2016, [Man is to Computer Programmer as Woman is to\n",
    "Homemaker? Debiasing Word Embeddings]\n",
    "\n",
    "#### 1. Identify bias direction (e.g. gender)\n",
    "- e(he) - e(she)\n",
    "- e(male) - e(female)\n",
    "- ...\n",
    "- Average = bias direction of gender\n",
    "\n",
    "#### 2. Neutralize gender-neutral words\n",
    "- gender-intrinsic (e.g. girl/boy, he/she) vs. gender-neutral (e.g. doctor, babysitter)\n",
    "- linear classifier to identify which words should be neutralized\n",
    "\n",
    "#### 3. Equalize pairs\n",
    "- e.g. grandmother and grandfather should have the same distance from gender-neutral words\n",
    "- hand-pick pairs to be equalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07656667  0.34967667 -0.40057667 -0.03130333  0.0088      0.72586333\n",
      "  0.10256     0.14906333  0.4780662  -0.22850987  0.05957667 -0.68663\n",
      "  0.62210033  0.10395     0.17747667  0.09556867 -0.49258333 -0.17066233\n",
      "  0.46930033  0.02196333  0.28145667  0.50513333  0.17144733  0.40154767\n",
      "  0.24039333  0.1646     -0.17984667  0.24042667  0.05689333 -0.31423\n",
      " -0.10933333  0.26355967  0.06100667 -0.01156405 -0.12236333 -0.188245\n",
      " -0.13215057 -0.068186    0.05624667 -0.29555567 -0.09669533 -0.29559667\n",
      "  0.62465867 -0.40130167  0.03330667 -0.24831667  0.26381667 -0.28738333\n",
      "  0.03020433  0.054106  ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate distance between gender pair woman-man\n",
    "woman_man = word_to_vec_map['woman'] - word_to_vec_map['man']\n",
    "\n",
    "# Calculate distance between gender pair mother-father\n",
    "mother_father = word_to_vec_map['mother'] - word_to_vec_map['father']\n",
    "\n",
    "# Calculate distance between gender pair girl-boy\n",
    "girl_boy = word_to_vec_map['girl'] - word_to_vec_map['boy']\n",
    "\n",
    "# Average over the gender pairs to get a simple representation of gender\n",
    "gender = np.average([woman_man, mother_father, girl_boy], axis=0)\n",
    "\n",
    "# Print gender vector\n",
    "print(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john -0.31\n",
      "marie 0.34\n",
      "sophie 0.41\n",
      "ronaldo -0.29\n",
      "priya 0.2\n",
      "rahul -0.19\n",
      "danielle 0.29\n",
      "reza -0.17\n",
      "katy 0.31\n",
      "yasmin 0.2\n"
     ]
    }
   ],
   "source": [
    "# Define girls and boys names for comparing the gender similarity\n",
    "name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n",
    "\n",
    "# Print results\n",
    "for w in name_list:\n",
    "    print (w, round(cosine_similarity(word_to_vec_map[w], gender), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lipstick 0.41\n",
      "guns -0.09\n",
      "science -0.06\n",
      "arts 0.01\n",
      "literature 0.02\n",
      "warrior -0.17\n",
      "doctor 0.08\n",
      "tree 0.04\n",
      "receptionist 0.3\n",
      "technology -0.16\n",
      "fashion 0.14\n",
      "teacher 0.11\n",
      "engineer -0.23\n",
      "pilot -0.04\n",
      "computer -0.17\n",
      "singer 0.2\n"
     ]
    }
   ],
   "source": [
    "# Define random words for comparing the gender similarity\n",
    "word_list = ['lipstick', 'guns', 'science', 'arts', 'literature', 'warrior','doctor', 'tree', 'receptionist', \n",
    "             'technology',  'fashion', 'teacher', 'engineer', 'pilot', 'computer', 'singer']\n",
    "\n",
    "# Print results (and look at the gender stereotypes!)\n",
    "for w in word_list:\n",
    "    print (w, round(cosine_similarity(word_to_vec_map[w], gender), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Bias Neutralization Algorithm (https://arxiv.org/abs/1607.06520)\n",
    "\n",
    "$$e^{bias\\_component} = \\frac{e \\cdot g}{||g||_2^2} * g\\tag{2}$$\n",
    "$$e^{debiased} = e - e^{bias\\_component}\\tag{3}$$\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize(word, g, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Removes the bias of \"word\" by projecting it on the space orthogonal to the bias axis. \n",
    "    This function ensures that gender neutral words are zero in the gender subspace.\n",
    "    \n",
    "    Arguments:\n",
    "        word -- string indicating the word to debias\n",
    "        g -- numpy-array of shape (50,), corresponding to the bias axis (such as gender)\n",
    "        word_to_vec_map -- dictionary mapping words to their corresponding vectors.\n",
    "    \n",
    "    Returns:\n",
    "        e_debiased -- neutralized word vector representation of the input \"word\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select word vector representation of \"word\". Use word_to_vec_map. \n",
    "    e = word_to_vec_map[word]\n",
    "    \n",
    "    # Compute e_biascomponent using the formula given above. \n",
    "    e_biascomponent = np.dot(np.dot(e, g) / np.sum(g ** 2), g)\n",
    " \n",
    "    # Neutralize e by subtracting e_biascomponent from it.\n",
    "    # e_debiased should be equal to its orthogonal projection.\n",
    "    e_debiased = e - e_biascomponent\n",
    "    \n",
    "    return e_debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity between receptionist and g, before neutralizing:  0.3\n",
      "cosine similarity between receptionist and g, after neutralizing:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Define a word and generate a gender-debiased version of it\n",
    "e = \"receptionist\"\n",
    "e_debiased = neutralize(e, gender, word_to_vec_map)\n",
    "\n",
    "# Print results\n",
    "print(\"cosine similarity between \" + e + \" and g, before neutralizing: \", round(cosine_similarity(word_to_vec_map[\"receptionist\"], gender), 2))\n",
    "print(\"cosine similarity between \" + e + \" and g, after neutralizing: \", round(cosine_similarity(e_debiased, gender), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Equalization Algorithm for Gender-specific Words (https://arxiv.org/abs/1607.06520)\n",
    "\n",
    "$$ \\mu = \\frac{e_{w1} + e_{w2}}{2} \\tag{4} $$ \n",
    "\n",
    "$$ \\mu_{B} = \\frac {\\mu \\cdot \\text{bias axis}}{||\\text{bias axis}||_2^2} *\\text{bias axis} \\tag{5} $$\n",
    "\n",
    "$$ \\mu_{\\perp} = \\mu - \\mu_{B} \\tag{6} $$\n",
    "\n",
    "$$ e_{w1B} = \\frac {e_{w1} \\cdot \\text{bias axis}}{||\\text{bias axis}||_2^2} *\\text{bias axis} \\tag{7} $$\n",
    "\n",
    "$$ e_{w2B} = \\frac {e_{w2} \\cdot \\text{bias axis}}{||\\text{bias axis}||_2^2} *\\text{bias axis} \\tag{8} $$\n",
    "\n",
    "$$e_{w1B}^{corrected} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{e_{\\text{w1B}} - \\mu_B} {||(e_{w1} - \\mu_{\\perp}) - \\mu_B||_2} \\tag{9} $$\n",
    "\n",
    "$$e_{w2B}^{corrected} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{e_{\\text{w2B}} - \\mu_B} {||(e_{w2} - \\mu_{\\perp}) - \\mu_B||_2} \\tag{10} $$\n",
    "\n",
    "$$e_1 = e_{w1B}^{corrected} + \\mu_{\\perp} \\tag{11} $$\n",
    "\n",
    "$$e_2 = e_{w2B}^{corrected} + \\mu_{\\perp} \\tag{12} $$\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(pair, bias_axis, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Debiases gender-specific words by following the equalize method described above.\n",
    "    \n",
    "    Arguments:\n",
    "    pair -- pair of strings of gender specific words to debias, e.g. (\"actress\", \"actor\") \n",
    "    bias_axis -- numpy-array of shape (50,), vector corresponding to the bias axis, e.g. gender\n",
    "    word_to_vec_map -- dictionary mapping words to their corresponding vectors\n",
    "    \n",
    "    Returns\n",
    "    e_1 -- word vector corresponding to the first word\n",
    "    e_2 -- word vector corresponding to the second word\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Select word vector representation of \"word\". Use word_to_vec_map\n",
    "    w1, w2 = pair\n",
    "    e_w1, e_w2 = word_to_vec_map[w1], word_to_vec_map[w2]\n",
    "    \n",
    "    # Step 2: Compute the mean of e_w1 and e_w2\n",
    "    mu = (e_w1 + e_w2) / 2\n",
    "\n",
    "    # Step 3: Compute the projections of mu over the bias axis and the orthogonal axis\n",
    "    mu_B = np.dot(np.dot(mu, bias_axis) / np.sum(bias_axis ** 2), bias_axis)\n",
    "    mu_orth = mu - mu_B\n",
    "\n",
    "    # Step 4: Use equations (7) and (8) to compute e_w1B and e_w2B \n",
    "    e_w1B = np.dot(np.dot(e_w1, bias_axis) / np.sum(bias_axis ** 2), bias_axis)\n",
    "    e_w2B = np.dot(np.dot(e_w2, bias_axis) / np.sum(bias_axis ** 2), bias_axis)\n",
    "        \n",
    "    # Step 5: Adjust the bias part of e_w1B and e_w2B using the formulas (9) and (10) given above \n",
    "    corrected_e_w1B = np.dot(np.sqrt(np.abs(1 - np.sum(mu_orth ** 2))), (e_w1B - mu_B) / np.linalg.norm(e_w1 - mu_orth - mu_B))\n",
    "    corrected_e_w2B = np.dot(np.sqrt(np.abs(1 - np.sum(mu_orth ** 2))), (e_w2B - mu_B) / np.linalg.norm(e_w2 - mu_orth - mu_B))\n",
    "\n",
    "    # Step 6: Debias by equalizing e1 and e2 to the sum of their corrected projections \n",
    "    e1 = corrected_e_w1B + mu_orth\n",
    "    e2 = corrected_e_w2B + mu_orth\n",
    "    \n",
    "    return e1, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarities before equalizing:\n",
      "cosine_similarity(word_to_vec_map[\"man\"], gender) =  -0.02\n",
      "cosine_similarity(word_to_vec_map[\"woman\"], gender) =  0.4\n",
      "\n",
      "cosine similarities after equalizing:\n",
      "cosine_similarity(e1, gender) =  -0.66\n",
      "cosine_similarity(e2, gender) =  0.66\n"
     ]
    }
   ],
   "source": [
    "print(\"cosine similarities before equalizing:\")\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"man\\\"], gender) = \", round(cosine_similarity(word_to_vec_map[\"man\"], gender), 2))\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"woman\\\"], gender) = \", round(cosine_similarity(word_to_vec_map[\"woman\"], gender), 2))\n",
    "\n",
    "print()\n",
    "e1, e2 = equalize((\"man\", \"woman\"), gender, word_to_vec_map)\n",
    "\n",
    "print(\"cosine similarities after equalizing:\")\n",
    "print(\"cosine_similarity(e1, gender) = \", round(cosine_similarity(e1, gender), 2))\n",
    "print(\"cosine_similarity(e2, gender) = \", round(cosine_similarity(e2, gender), 2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
