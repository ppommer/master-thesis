{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- second example and bias axis (next to gender)\n",
    "- hypothesis\n",
    "- BERT\n",
    "- Repo-Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 18:51:28.851034: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-18 18:51:28.851128: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe (Global Vectors for Word Representation)\n",
    "\n",
    "Paper: https://nlp.stanford.edu/pubs/glove.pdf\n",
    "\n",
    "Pre-trained word vectors: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:06, 60743.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read GloVe vectors into a word-to-vec dictionary\n",
    "glove_map = read_glove_vecs(\"data/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT (Bidirectional Encoder Representations from Transformers)\n",
    "Paper: https://arxiv.org/pdf/1810.04805.pdf\n",
    "\n",
    "Implementation: https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.14it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = [\"man\", \"doctor\", \"woman\", \"nurse\", \"italy\", \"italian\", \"spain\", \"india\", \"delhi\", \"japan\", \"man\", \"woman\", \"boy\", \"small\", \"smaller\", \"large\", \"mother\", \"father\", \"girl\", \"boy\", \"john\", \"marie\", \"sophie\", \"ronaldo\", \"priya\", \"rahul\", \"danielle\", \"reza\", \"katy\", \"yasmin\", \"lipstick\", \"guns\", \"science\", \"arts\", \"literature\", \"warrior\",\"doctor\", \"tree\", \"receptionist\", \"technology\",  \"fashion\", \"teacher\", \"engineer\", \"pilot\", \"computer\", \"singer\", \"receptionist\"]\n",
    "bert_map = create_bert_map(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity and cosine distance\n",
    "\n",
    "The cosine similarity is a measure for similarity between two vectors. It always belongs to the interval [-1, 1] and is defined as follows:\n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u \\cdot v} {||u||_2 ||v||_2} = cos(\\theta) \\tag{1}$$\n",
    "\n",
    "\n",
    "The cosine distance lies in [0, 2] and is defined by \n",
    "\n",
    "$$\\text{CosineDistance(u, v)} = 1 - \\text{CosineSimilarity(u, v)}\\tag{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man-doctor:    0.29\n",
      "woman-nurse:   0.28\n",
      "man-woman:     0.11\n",
      "doctor-nurse:  0.20\n",
      "man-nurse:     0.43\n",
      "man-nurse:     0.43\n",
      "woman-doctor:  0.27\n",
      "\n",
      "man -> doctor :: woman -> nurse:   0.00\n",
      "man -> nurse :: woman -> doctor:   0.15\n"
     ]
    }
   ],
   "source": [
    "dyads = [\n",
    "    (\"man\", \"doctor\"),\n",
    "    (\"woman\", \"nurse\"),\n",
    "    (\"man\", \"woman\"),\n",
    "    (\"doctor\", \"nurse\"),\n",
    "    (\"man\", \"nurse\"),\n",
    "    (\"man\", \"nurse\"),\n",
    "    (\"woman\", \"doctor\")\n",
    "]\n",
    "\n",
    "quartets = [\n",
    "    (\"man\", \"doctor\", \"woman\", \"nurse\"),\n",
    "    (\"man\", \"nurse\", \"woman\", \"doctor\")\n",
    "]\n",
    "\n",
    "# Print cosine similarity for each dyad\n",
    "for dyad in dyads:\n",
    "    print(\"{:<13}{:>6,.2f}\".format(str(dyad[0]) + \"-\" + str(dyad[1]) + \":\", cosine(glove_map[dyad[0]], glove_map[dyad[1]])))\n",
    "\n",
    "print()\n",
    "\n",
    "# Print cosine similarity between the dyads in each quartet to demonstrate gender bias\n",
    "for quartet in quartets:\n",
    "    print(\"{} -> {} :: {} -> {}: {:>6,.2f}\".format(*quartet, cosine(glove_map[quartet[0]], glove_map[quartet[1]]) - cosine(glove_map[quartet[2]], glove_map[quartet[3]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 18:51:39.968904: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-18 18:51:39.968996: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-18 18:51:39.969068: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (zenbook): /proc/driver/nvidia/version does not exist\n",
      "2022-03-18 18:51:39.969702: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define words for which embeddings should be visualized\n",
    "words = [\"man\", \"doctor\", \"woman\", \"nurse\"]\n",
    "\n",
    "# Create word-to-vec map\n",
    "map = {}\n",
    "for word in words:\n",
    "    map[word] = glove_map[word]\n",
    "\n",
    "# Create the log file for the TensorBoard visualization\n",
    "visualize_embedding(word_to_vec_map=map, dir_name=\"glove_gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard # select logs dir and go to \"Projector\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogies\n",
    "\n",
    "Performs the word analogy task \"a is to b as c is to ...\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: spain -> spanish\n",
      "india -> delhi :: japan -> tokyo\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> smaller\n"
     ]
    }
   ],
   "source": [
    "# Define triads to try analogies\n",
    "triads = [\n",
    "    (\"italy\", \"italian\", \"spain\"),\n",
    "    (\"india\", \"delhi\", \"japan\"),\n",
    "    (\"man\", \"woman\", \"boy\"),\n",
    "    (\"small\", \"smaller\", \"large\")\n",
    "]\n",
    "\n",
    "# Print results\n",
    "for triad in triads:\n",
    "    print (\"{} -> {} :: {} -> {}\".format(*triad, complete_analogy(*triad, glove_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define words for which embeddings should be visualized\n",
    "words = [\"italy\", \"italian\", \"spain\", \"spanish\", \"india\", \"delhi\", \"japan\", \"tokyo\"]\n",
    "\n",
    "# Create word-to-vec map\n",
    "map = {}\n",
    "for word in words:\n",
    "    map[word] = glove_map[word]\n",
    "\n",
    "# Create the log file for the TensorBoard visualization\n",
    "visualize_embedding(word_to_vec_map=map, dir_name=\"glove_countries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard # select logs dir and go to \"Projector\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The debiasing algorithm is from Bolukbasi et al. (2016), Man is to Computer Programmer as Woman is to\n",
    "Homemaker? Debiasing Word Embeddings (https://arxiv.org/abs/1607.06520)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Identify bias direction (e.g. gender)\n",
    "- e(he) - e(she)\n",
    "- e(male) - e(female)\n",
    "- ...\n",
    "- Average = bias direction of gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance between gender pair woman-man\n",
    "woman_man = glove_map[\"woman\"] - glove_map[\"man\"]\n",
    "\n",
    "# Calculate distance between gender pair mother-father\n",
    "mother_father = glove_map[\"mother\"] - glove_map[\"father\"]\n",
    "\n",
    "# Calculate distance between gender pair girl-boy\n",
    "girl_boy = glove_map[\"girl\"] - glove_map[\"boy\"]\n",
    "\n",
    "# Average over the gender pairs to get a simple representation of gender\n",
    "gender = np.average([woman_man, mother_father, girl_boy], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john:      1.31\n",
      "marie:     0.66\n",
      "sophie:    0.59\n",
      "ronaldo:   1.29\n",
      "priya:     0.80\n",
      "rahul:     1.19\n",
      "danielle:  0.71\n",
      "reza:      1.17\n",
      "katy:      0.69\n",
      "yasmin:    0.80\n"
     ]
    }
   ],
   "source": [
    "# Define girls and boys names for comparing the gender similarity\n",
    "name_list = [\"john\", \"marie\", \"sophie\", \"ronaldo\", \"priya\", \"rahul\", \"danielle\", \"reza\", \"katy\", \"yasmin\"]\n",
    "\n",
    "# Print results\n",
    "for w in name_list:\n",
    "    print(\"{:<9}{:>6,.2f}\".format(w + \":\", cosine(glove_map[w], gender)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lipstick:      0.59\n",
      "guns:          1.09\n",
      "science:       1.06\n",
      "arts:          0.99\n",
      "literature:    0.98\n",
      "warrior:       1.17\n",
      "doctor:        0.92\n",
      "tree:          0.96\n",
      "receptionist:  0.70\n",
      "technology:    1.16\n",
      "fashion:       0.86\n",
      "teacher:       0.89\n",
      "engineer:      1.23\n",
      "pilot:         1.04\n",
      "computer:      1.17\n",
      "singer:        0.80\n"
     ]
    }
   ],
   "source": [
    "# Define random words for comparing the gender similarity\n",
    "word_list = [\"lipstick\", \"guns\", \"science\", \"arts\", \"literature\", \"warrior\",\"doctor\", \"tree\", \"receptionist\", \n",
    "             \"technology\",  \"fashion\", \"teacher\", \"engineer\", \"pilot\", \"computer\", \"singer\"]\n",
    "\n",
    "# Print results (and look at the gender stereotypes!)\n",
    "for w in word_list:\n",
    "    print(\"{:<13}{:>6,.2f}\".format(w + \":\", cosine(glove_map[w], gender)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Neutralize gender-neutral words\n",
    "- gender-intrinsic (e.g. girl/boy, he/she) vs. gender-neutral (e.g. doctor, babysitter)\n",
    "- linear classifier to identify which words should be neutralized\n",
    "\n",
    "$$e^{bias\\_component} = \\frac{e \\cdot g}{||g||_2^2} * g\\tag{3}$$\n",
    "$$e^{debiased} = e - e^{bias\\_component}\\tag{4}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity before equalizing:\n",
      "receptionist-gender:  0.70\n",
      "\n",
      "Cosine similarity after equalizing:\n",
      "receptionist-gender:  1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity before equalizing:\")\n",
    "print(\"{:<20}{:>6,.2f}\".format(\"receptionist-gender:\", cosine(glove_map[\"receptionist\"], gender)))\n",
    "\n",
    "e_debiased = neutralize(\"receptionist\", gender, glove_map)\n",
    "\n",
    "print()\n",
    "print(\"Cosine similarity after equalizing:\")\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"receptionist-gender:\", cosine(e_debiased, gender)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Equalize pairs\n",
    "- e.g. grandmother and grandfather should have the same distance from gender-neutral words\n",
    "- hand-pick pairs to be equalized\n",
    "\n",
    "$$ \\mu = \\frac{e_{w1} + e_{w2}}{2} \\tag{5} $$ \n",
    "\n",
    "$$ \\mu_{B} = \\frac {\\mu \\cdot \\text{bias axis}}{||\\text{bias axis}||_2^2} *\\text{bias axis} \\tag{6} $$\n",
    "\n",
    "$$ \\mu_{\\perp} = \\mu - \\mu_{B} \\tag{7} $$\n",
    "\n",
    "$$ e_{w1B} = \\frac {e_{w1} \\cdot \\text{bias axis}}{||\\text{bias axis}||_2^2} *\\text{bias axis} \\tag{8} $$\n",
    "\n",
    "$$ e_{w2B} = \\frac {e_{w2} \\cdot \\text{bias axis}}{||\\text{bias axis}||_2^2} *\\text{bias axis} \\tag{9} $$\n",
    "\n",
    "$$e_{w1B}^{corrected} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{e_{\\text{w1B}} - \\mu_B} {||(e_{w1} - \\mu_{\\perp}) - \\mu_B||_2} \\tag{10} $$\n",
    "\n",
    "$$e_{w2B}^{corrected} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{e_{\\text{w2B}} - \\mu_B} {||(e_{w2} - \\mu_{\\perp}) - \\mu_B||_2} \\tag{11} $$\n",
    "\n",
    "$$e_1 = e_{w1B}^{corrected} + \\mu_{\\perp} \\tag{12} $$\n",
    "\n",
    "$$e_2 = e_{w2B}^{corrected} + \\mu_{\\perp} \\tag{13} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities before equalizing:\n",
      "man-gender:    1.02\n",
      "woman-gender:  0.60\n",
      "\n",
      "Cosine similarities after equalizing:\n",
      "man-gender:    1.66\n",
      "woman-gender:  0.34\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarities before equalizing:\")\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"man-gender:\", cosine(glove_map[\"man\"], gender)))\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"woman-gender:\", cosine(glove_map[\"woman\"], gender)))\n",
    "\n",
    "e1, e2 = equalize((\"man\", \"woman\"), gender, glove_map)\n",
    "\n",
    "print()\n",
    "print(\"Cosine similarities after equalizing:\")\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"man-gender:\", cosine(e1, gender)))\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"woman-gender:\", cosine(e2, gender)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
