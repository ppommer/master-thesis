{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 16:34:54.320937: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-22 16:34:54.320978: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe (Global Vectors for Word Representation)\n",
    "\n",
    "Paper: https://nlp.stanford.edu/pubs/glove.pdf\n",
    "\n",
    "Pre-trained word vectors: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5aaca8c6084e548d516a29ae6a3f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read GloVe vectors into a word-to-vec dictionary\n",
    "glove_map = read_glove_vecs(\"data/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT (Bidirectional Encoder Representations from Transformers)\n",
    "Paper: https://aclanthology.org/N19-1423/\n",
    "\n",
    "Implementation: https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a66e9b9d40646f388ebc4cecb375fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = [\"man\", \"doctor\", \"woman\", \"nurse\", \"italy\", \"italian\", \"spain\", \"spanish\", \"india\", \"delhi\", \"japan\", \"tokyo\", \"man\", \"woman\", \"boy\", \"small\", \"smaller\", \"large\", \"mother\", \"father\", \"girl\", \"boy\", \"john\", \"marie\", \"sophie\", \"ronaldo\", \"priya\", \"rahul\", \"danielle\", \"reza\", \"katy\", \"yasmin\", \"lipstick\", \"guns\", \"science\", \"arts\", \"literature\", \"warrior\",\"doctor\", \"tree\", \"receptionist\", \"technology\",  \"fashion\", \"teacher\", \"engineer\", \"pilot\", \"computer\", \"singer\", \"receptionist\"]\n",
    "bert_map = create_bert_map(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity and cosine distance\n",
    "\n",
    "The cosine similarity is a measure for similarity between two vectors. It always belongs to the interval [-1, 1] and is defined as follows:\n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u \\cdot v} {||u||_2 ||v||_2} = cos(\\theta)Â \\tag{1}$$\n",
    "\n",
    "\n",
    "The cosine distance lies in [0, 2] and is defined by \n",
    "\n",
    "$$\\text{CosineDistance(u, v)} = 1 - \\text{CosineSimilarity(u, v)}\\tag{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              GloVe  BERT\n",
      "man-doctor:    0.29  0.13\n",
      "woman-nurse:   0.28  0.11\n",
      "man-woman:     0.11  0.09\n",
      "doctor-nurse:  0.20  0.06\n",
      "man-nurse:     0.43  0.15\n",
      "woman-doctor:  0.27  0.11\n",
      "\n",
      "                                  GloVe  BERT\n",
      "man -> doctor :: woman -> nurse:   0.00  0.18\n",
      "man -> nurse :: woman -> doctor:   0.15  0.32\n"
     ]
    }
   ],
   "source": [
    "dyads = [\n",
    "    (\"man\", \"doctor\"),\n",
    "    (\"woman\", \"nurse\"),\n",
    "    (\"man\", \"woman\"),\n",
    "    (\"doctor\", \"nurse\"),\n",
    "    (\"man\", \"nurse\"),\n",
    "    (\"woman\", \"doctor\")\n",
    "]\n",
    "\n",
    "quartets = [\n",
    "    (\"man\", \"doctor\", \"woman\", \"nurse\"),\n",
    "    (\"man\", \"nurse\", \"woman\", \"doctor\")\n",
    "]\n",
    "\n",
    "# Print cosine similarity for each dyad\n",
    "print(\"{:<13}{:>6}{:>6}\".format(\"\", \"GloVe\", \"BERT\"))\n",
    "for dyad in dyads:\n",
    "    print(\"{:<13}{:>6,.2f}{:>6,.2f}\".format(str(dyad[0]) + \"-\" + str(dyad[1]) + \":\", cosine(glove_map[dyad[0]], glove_map[dyad[1]]), cosine(bert_map[dyad[0]], bert_map[dyad[1]])))\n",
    "\n",
    "print()\n",
    "\n",
    "# Print cosine similarity between the dyads in each quartet to demonstrate gender bias\n",
    "print(\"{:<33}{:>6}{:>6}\".format(\"\", \"GloVe\", \"BERT\"))\n",
    "for quartet in quartets:\n",
    "    print(\"{} -> {} :: {} -> {}: {:>6,.2f}{:>6,.2f}\".format(*quartet, cosine(glove_map[quartet[0]], glove_map[quartet[1]]) - cosine(glove_map[quartet[2]], glove_map[quartet[3]]), cosine(glove_map[quartet[0]], glove_map[quartet[1]]) - cosine(bert_map[quartet[2]], bert_map[quartet[3]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 16:35:19.380414: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-22 16:35:19.380506: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-22 16:35:19.380569: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (zenbook): /proc/driver/nvidia/version does not exist\n",
      "2022-03-22 16:35:19.381411: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# Define words for which embeddings should be visualized\n",
    "words = [\"man\", \"doctor\", \"woman\", \"nurse\"]\n",
    "\n",
    "# Create word-to-vec map from GloVe\n",
    "glove_gender = {}\n",
    "for word in words:\n",
    "    glove_gender[word] = glove_map[word]\n",
    "\n",
    "# Create word-to-vec map from BERT\n",
    "bert_gender = {}\n",
    "for word in words:\n",
    "    bert_gender[word] = bert_map[word]\n",
    "\n",
    "# Create the log file for the TensorBoard visualization\n",
    "visualize_embedding(word_to_vec_map=glove_gender, dir_name=\"glove_gender\")\n",
    "visualize_embedding(word_to_vec_map=bert_gender, dir_name=\"bert_gender\")\n",
    "\n",
    "%tensorboard --logdir \"./logs/glove_gender\"\n",
    "%tensorboard --logdir \"./logs/bert_gender\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogies\n",
    "\n",
    "Performs the word analogy task \"a is to b as c is to ...\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ff971ca9e340b6bf0c5d21ba89e713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: spain -> spanish\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a985b71a6f41d8b44028ec3a24d9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india -> delhi :: japan -> tokyo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d99f92513e44743b96ba54af31ff4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man -> woman :: boy -> girl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb6c26e005646d59ae2c6f7c742ba25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small -> smaller :: large -> smaller\n",
      "\n",
      "BERT:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546e2077e78748878c6ddb4d01403491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: spain -> spanish\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d0d0987d4b4cfebfb8588758df674e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india -> delhi :: japan -> delhi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad56d15d9c546f4a9d69afaeb1db9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man -> woman :: boy -> woman\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787fa8a4edb641bc998fd3586e874fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small -> smaller :: large -> smaller\n"
     ]
    }
   ],
   "source": [
    "# Define triads to try analogies\n",
    "triads = [\n",
    "    (\"italy\", \"italian\", \"spain\"),\n",
    "    (\"india\", \"delhi\", \"japan\"),\n",
    "    (\"man\", \"woman\", \"boy\"),\n",
    "    (\"small\", \"smaller\", \"large\"),\n",
    "]\n",
    "\n",
    "# Print results\n",
    "print(\"GloVe:\")\n",
    "for triad in triads:\n",
    "    print (\"{} -> {} :: {} -> {}\".format(*triad, complete_analogy(*triad, glove_map)))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"BERT:\")\n",
    "for triad in triads:\n",
    "    print (\"{} -> {} :: {} -> {}\".format(*triad, complete_analogy(*triad, bert_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# Define words for which embeddings should be visualized\n",
    "words = [\"italy\", \"italian\", \"spain\", \"spanish\", \"india\", \"delhi\", \"japan\", \"tokyo\"]\n",
    "\n",
    "# Create word-to-vec map from GloVe\n",
    "glove_countries = {}\n",
    "for word in words:\n",
    "    glove_countries[word] = glove_map[word]\n",
    "\n",
    "# Create word-to-vec map from BERT\n",
    "bert_countries = {}\n",
    "for word in words:\n",
    "    bert_countries[word] = bert_map[word]\n",
    "\n",
    "# Create the log file for the TensorBoard visualization\n",
    "visualize_embedding(word_to_vec_map=glove_countries, dir_name=\"glove_countries\")\n",
    "visualize_embedding(word_to_vec_map=bert_countries, dir_name=\"bert_countries\")\n",
    "\n",
    "%tensorboard --logdir \"./logs/glove_countries\"\n",
    "%tensorboard --logdir \"./logs/bert_countries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The debiasing algorithm is from Bolukbasi et al. (2016), Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings (https://arxiv.org/abs/1607.06520)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Identify bias direction (e.g. gender)\n",
    "- e(he) - e(she)\n",
    "- e(male) - e(female)\n",
    "- ...\n",
    "- Average = bias direction of gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance between gender pair woman-man\n",
    "woman_man = glove_map[\"woman\"] - glove_map[\"man\"]\n",
    "\n",
    "# Calculate distance between gender pair mother-father\n",
    "mother_father = glove_map[\"mother\"] - glove_map[\"father\"]\n",
    "\n",
    "# Calculate distance between gender pair girl-boy\n",
    "girl_boy = glove_map[\"girl\"] - glove_map[\"boy\"]\n",
    "\n",
    "# Average over the gender pairs to get a simple representation of gender\n",
    "gender = np.average([woman_man, mother_father, girl_boy], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john:      1.31\n",
      "marie:     0.66\n",
      "sophie:    0.59\n",
      "ronaldo:   1.29\n",
      "priya:     0.80\n",
      "rahul:     1.19\n",
      "danielle:  0.71\n",
      "reza:      1.17\n",
      "katy:      0.69\n",
      "yasmin:    0.80\n"
     ]
    }
   ],
   "source": [
    "# Define girls and boys names for comparing the gender similarity\n",
    "name_list = [\"john\", \"marie\", \"sophie\", \"ronaldo\", \"priya\", \"rahul\", \"danielle\", \"reza\", \"katy\", \"yasmin\"]\n",
    "\n",
    "# Print results\n",
    "for w in name_list:\n",
    "    print(\"{:<9}{:>6,.2f}\".format(w + \":\", cosine(glove_map[w], gender)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lipstick:      0.59\n",
      "guns:          1.09\n",
      "science:       1.06\n",
      "arts:          0.99\n",
      "literature:    0.98\n",
      "warrior:       1.17\n",
      "doctor:        0.92\n",
      "tree:          0.96\n",
      "receptionist:  0.70\n",
      "technology:    1.16\n",
      "fashion:       0.86\n",
      "teacher:       0.89\n",
      "engineer:      1.23\n",
      "pilot:         1.04\n",
      "computer:      1.17\n",
      "singer:        0.80\n"
     ]
    }
   ],
   "source": [
    "# Define random words for comparing the gender similarity\n",
    "word_list = [\"lipstick\", \"guns\", \"science\", \"arts\", \"literature\", \"warrior\",\"doctor\", \"tree\", \"receptionist\", \n",
    "             \"technology\",  \"fashion\", \"teacher\", \"engineer\", \"pilot\", \"computer\", \"singer\"]\n",
    "\n",
    "# Print results (and look at the gender stereotypes!)\n",
    "for w in word_list:\n",
    "    print(\"{:<13}{:>6,.2f}\".format(w + \":\", cosine(glove_map[w], gender)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Neutralize gender-neutral words\n",
    "- gender-intrinsic (e.g. girl/boy, he/she) vs. gender-neutral (e.g. doctor, babysitter)\n",
    "- linear classifier to identify which words should be neutralized\n",
    "\n",
    "$$e^{bias\\_component} = \\frac{e \\cdot g}{||g||_2^2} * g\\tag{3}$$\n",
    "$$e^{debiased} = e - e^{bias\\_component}\\tag{4}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity before equalizing:\n",
      "receptionist-gender:  0.70\n",
      "\n",
      "Cosine similarity after equalizing:\n",
      "receptionist-gender:  1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity before equalizing:\")\n",
    "print(\"{:<20}{:>6,.2f}\".format(\"receptionist-gender:\", cosine(glove_map[\"receptionist\"], gender)))\n",
    "\n",
    "e_debiased = neutralize(\"receptionist\", gender, glove_map)\n",
    "\n",
    "print()\n",
    "print(\"Cosine similarity after equalizing:\")\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"receptionist-gender:\", cosine(e_debiased, gender)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Equalize pairs\n",
    "- e.g. grandmother and grandfather should have the same distance from gender-neutral words\n",
    "- pairs to be equalized have to be hand-picked\n",
    "\n",
    "$$ \\mu = \\frac{e_{w1} + e_{w2}}{2} \\tag{5} $$ \n",
    "\n",
    "$$ \\mu_{B} = \\frac {\\mu \\cdot \\text{bias axis}}{||\\text{bias axis}||_2^2} *\\text{bias axis} \\tag{6} $$\n",
    "\n",
    "$$ \\mu_{\\perp} = \\mu - \\mu_{B} \\tag{7} $$\n",
    "\n",
    "$$ e_{w1B} = \\frac {e_{w1} \\cdot \\text{bias axis}}{||\\text{bias axis}||_2^2} *\\text{bias axis} \\tag{8} $$\n",
    "\n",
    "$$ e_{w2B} = \\frac {e_{w2} \\cdot \\text{bias axis}}{||\\text{bias axis}||_2^2} *\\text{bias axis} \\tag{9} $$\n",
    "\n",
    "$$e_{w1B}^{corrected} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{e_{\\text{w1B}} - \\mu_B} {||(e_{w1} - \\mu_{\\perp}) - \\mu_B||_2} \\tag{10} $$\n",
    "\n",
    "$$e_{w2B}^{corrected} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{e_{\\text{w2B}} - \\mu_B} {||(e_{w2} - \\mu_{\\perp}) - \\mu_B||_2} \\tag{11} $$\n",
    "\n",
    "$$e_1 = e_{w1B}^{corrected} + \\mu_{\\perp} \\tag{12} $$\n",
    "\n",
    "$$e_2 = e_{w2B}^{corrected} + \\mu_{\\perp} \\tag{13} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities before equalizing:\n",
      "man-gender:    1.02\n",
      "woman-gender:  0.60\n",
      "\n",
      "Cosine similarities after equalizing:\n",
      "man-gender:    1.66\n",
      "woman-gender:  0.34\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarities before equalizing:\")\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"man-gender:\", cosine(glove_map[\"man\"], gender)))\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"woman-gender:\", cosine(glove_map[\"woman\"], gender)))\n",
    "\n",
    "e1, e2 = equalize((\"man\", \"woman\"), gender, glove_map)\n",
    "\n",
    "print()\n",
    "print(\"Cosine similarities after equalizing:\")\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"man-gender:\", cosine(e1, gender)))\n",
    "print(\"{:<13}{:>6,.2f}\".format(\"woman-gender:\", cosine(e2, gender)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias in BERT\n",
    "\n",
    "following https://analyticsindiamag.com/a-complete-tutorial-on-masked-language-modelling-using-bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model = pipeline(\"fill-mask\", model=\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lawful is to Christianity as terrorist is to Islam.\n",
      "White people tend to be policemen whereas black people tend to be policemen.\n",
      "\n",
      "He can work as a mechanic.\n",
      "He can work as a lawyer.\n",
      "He can work as a waiter.\n",
      "He can work as a detective.\n",
      "He can work as a pilot.\n",
      "\n",
      "She can work as a waitress.\n",
      "She can work as a nurse.\n",
      "She can work as a maid.\n",
      "She can work as a model.\n",
      "She can work as a lawyer.\n"
     ]
    }
   ],
   "source": [
    "pred = model(\"Lawful is to Christianity as terrorist is to [MASK].\")\n",
    "print(pred[0][\"sequence\"])\n",
    "\n",
    "pred = model(\"White people tend to be policemen whereas black people tend to be [MASK].\")\n",
    "print(pred[0][\"sequence\"])\n",
    "\n",
    "print()\n",
    "\n",
    "pred = model(\"He can work as a [MASK].\")\n",
    "for p in pred:\n",
    "    print(p[\"sequence\"])\n",
    "\n",
    "print()\n",
    "\n",
    "pred = model(\"She can work as a [MASK].\")\n",
    "for p in pred:\n",
    "    print(p[\"sequence\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
